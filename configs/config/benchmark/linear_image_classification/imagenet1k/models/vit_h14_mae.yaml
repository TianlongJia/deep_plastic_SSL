# @package _global_
config:
  DATA:
    TRAIN:
      BATCHSIZE_PER_REPLICA: 256
      TRANSFORMS:
        - name: RandomResizedCrop
          size: 224
          interpolation: 3
        - name: RandomHorizontalFlip
        - name: ToTensor
        - name: Normalize
          mean: [0.485, 0.456, 0.406]
          std: [0.229, 0.224, 0.225]
    TEST:
      BATCHSIZE_PER_REPLICA: 256
      TRANSFORMS:
        - name: Resize
          size: 256
          interpolation: 3
        - name: CenterCrop
          size: 224
        - name: ToTensor
        - name: Normalize
          mean: [0.485, 0.456, 0.406]
          std: [0.229, 0.224, 0.225]
  MODEL:
    FEATURE_EVAL_SETTINGS:
      LINEAR_EVAL_FEAT_POOL_OPS_MAP: [
        # ["concatPOOL4", ["Identity", []] ],
        # ["lastPOOL", ["Identity", []] ],
        # ["concatCLS4", ["Identity", []] ],
        ["lastCLS", ["Identity", []] ],
      ]
    TRUNK: # H-14
      NAME: vision_transformer
      VISION_TRANSFORMERS:
        IMAGE_SIZE: 224
        PATCH_SIZE: 14
        NUM_LAYERS: 32
        NUM_HEADS: 16
        HIDDEN_DIM: 1280
        MLP_DIM: 5120
        DROPOUT_RATE: 0
        ATTENTION_DROPOUT_RATE: 0
        QKV_BIAS: True
        DROP_PATH_RATE: 0.3
    HEAD:
      PARAMS: [
        # ["eval_mlp", {"in_channels": 5120, "dims": [5120, 1000]}],
        # ["eval_mlp", {"in_channels": 1280, "dims": [1280, 1000]}],
        # ["eval_mlp", {"in_channels": 5120, "dims": [5120, 1000]}],
        ["eval_mlp", {"in_channels": 1280, "dims": [1280, 1000]}],
      ]
  OPTIMIZER:
    name: lars
    momentum: 0.9
    weight_decay: 0.0
    num_epochs: 50
    exclude_bias_and_norm: true
    param_schedulers:
      lr:
        auto_lr_scaling:
          auto_scale: true
          base_value: 0.1
          base_lr_batch_size: 256
        name: composite
        schedulers:
          - name: linear
            start_value: 1e-6
            end_value: 0.1
          - name: cosine
            start_value: 0.1
            end_value: 1e-6
        interval_scaling: [rescaled, rescaled]
        update_interval: step
        lengths: [0.2, 0.8] # 10 warmup epochs
    # param_group_constructor: linear_eval_heads
    # linear_eval_heads:
    #   - {"lr": 1.0, "weight_decay": 0.0}
    #   - {"lr": 1.0, "weight_decay": 0.0}
    #   - {"lr": 1.0, "weight_decay": 0.0}
    #   - {"lr": 1.0, "weight_decay": 0.0}
  DISTRIBUTED:
    NUM_NODES: 8
    NUM_PROC_PER_NODE: 8

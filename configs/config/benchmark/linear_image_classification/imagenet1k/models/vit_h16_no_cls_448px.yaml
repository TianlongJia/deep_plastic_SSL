# @package _global_
config:
  DATA:
    TRAIN:
      BATCHSIZE_PER_REPLICA: 32
      TRANSFORMS:
        - name: RandomResizedCrop
          size: 448
          interpolation: 3
        - name: RandomHorizontalFlip
        - name: ToTensor
        - name: Normalize
          mean: [0.485, 0.456, 0.406]
          std: [0.229, 0.224, 0.225]
    TEST:
      BATCHSIZE_PER_REPLICA: 32
      TRANSFORMS:
        - name: Resize
          size: 512
          interpolation: 3
        - name: CenterCrop
          size: 448
        - name: ToTensor
        - name: Normalize
          mean: [0.485, 0.456, 0.406]
          std: [0.229, 0.224, 0.225]
  MODEL:
    FEATURE_EVAL_SETTINGS:
      LINEAR_EVAL_FEAT_POOL_OPS_MAP: [
        ["concatPOOL4", ["Identity", []] ],
        ["concatPOOL4", ["Identity", []] ],
        ["lastPOOL", ["Identity", []] ],
        ["lastPOOL", ["Identity", []] ],
        ["concatPOOL4", ["Identity", []] ],
        ["concatPOOL4", ["Identity", []] ],
        ["lastPOOL", ["Identity", []] ],
        ["lastPOOL", ["Identity", []] ],
        ["concatPOOL4", ["Identity", []] ],
        ["concatPOOL4", ["Identity", []] ],
        ["lastPOOL", ["Identity", []] ],
        ["lastPOOL", ["Identity", []] ],
        ["concatPOOL4", ["Identity", []] ],
        ["concatPOOL4", ["Identity", []] ],
        ["lastPOOL", ["Identity", []] ],
        ["lastPOOL", ["Identity", []] ],
      ]
    TRUNK: # H-16
      NAME: vision_transformer
      VISION_TRANSFORMERS:
        IMAGE_SIZE: 448
        PATCH_SIZE: 16
        NUM_LAYERS: 32
        NUM_HEADS: 16
        HIDDEN_DIM: 1280
        MLP_DIM: 5120
        DROPOUT_RATE: 0
        ATTENTION_DROPOUT_RATE: 0
        CLASSIFIER: token
        QKV_BIAS: True
        DROP_PATH_RATE: 0.0
        USE_CLASS_TOKEN: False
    HEAD:
      PARAMS: [
        ["eval_mlp", {"in_channels": 5120, "dims": [5120, 1000]}],
        ["mlp", {"dims": [5120, 1000]}],
        ["eval_mlp", {"in_channels": 1280, "dims": [1280, 1000]}],
        ["mlp", {"dims": [1280, 1000]}],
        ["eval_mlp", {"in_channels": 5120, "dims": [5120, 1000]}],
        ["mlp", {"dims": [5120, 1000]}],
        ["eval_mlp", {"in_channels": 1280, "dims": [1280, 1000]}],
        ["mlp", {"dims": [1280, 1000]}],
        ["eval_mlp", {"in_channels": 5120, "dims": [5120, 1000]}],
        ["mlp", {"dims": [5120, 1000]}],
        ["eval_mlp", {"in_channels": 1280, "dims": [1280, 1000]}],
        ["mlp", {"dims": [1280, 1000]}],
        ["eval_mlp", {"in_channels": 5120, "dims": [5120, 1000]}],
        ["mlp", {"dims": [5120, 1000]}],
        ["eval_mlp", {"in_channels": 1280, "dims": [1280, 1000]}],
        ["mlp", {"dims": [1280, 1000]}],
      ]
  OPTIMIZER:
    # name: lars
    # momentum: 0.9
    # weight_decay: 0.0
    # num_epochs: 50
    # exclude_bias_and_norm: true
    # param_schedulers:
    #  lr:
    #    auto_lr_scaling:
    #      auto_scale: true
    #      base_value: 0.1
    #      base_lr_batch_size: 256
    #    name: multistep
    #    values: [0.1, 0.01, 0.001, 0.0001]
    #    milestones: [15, 30, 45]
    #    update_interval: epoch
    param_group_constructor: linear_eval_heads
    linear_eval_heads:
      - {"lr": 1.0, "weight_decay": 0.0005}
      - {"lr": 1.0, "weight_decay": 0.0005}
      - {"lr": 1.0, "weight_decay": 0.0005}
      - {"lr": 1.0, "weight_decay": 0.0005}
      - {"lr": 1.0, "weight_decay": 0.0}
      - {"lr": 1.0, "weight_decay": 0.0}
      - {"lr": 1.0, "weight_decay": 0.0}
      - {"lr": 1.0, "weight_decay": 0.0}
      - {"lr": 0.1, "weight_decay": 0.0005}
      - {"lr": 0.1, "weight_decay": 0.0005}
      - {"lr": 0.1, "weight_decay": 0.0005}
      - {"lr": 0.1, "weight_decay": 0.0005}
      - {"lr": 0.1, "weight_decay": 0.0}
      - {"lr": 0.1, "weight_decay": 0.0}
      - {"lr": 0.1, "weight_decay": 0.0}
      - {"lr": 0.1, "weight_decay": 0.0}
  # DISTRIBUTED:
  #   NUM_NODES: 8
  #   NUM_PROC_PER_NODE: 8
